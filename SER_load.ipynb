{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SER_load.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1SdI7iJMHgSNV9XMsUwm3FYyHverk4sw3",
      "authorship_tag": "ABX9TyPZtPe6Pr3bvFxpmZpfIZSm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValeryNikiforov/Speech-Emotion-Recognition/blob/master/SER_load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QXbhjK9DzCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy\n",
        "import scipy.io.wavfile\n",
        "from scipy.fftpack import dct\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Audio\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoklHGZTEvpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "catalog_name = 'drive/My Drive/toronto_converted/'\n",
        "catalog_name_rav = 'drive/My Drive/ravdess_converted/'\n",
        "catalog_name_sav = 'drive/My Drive/savdee_converted/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eCWaq6kMD3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w5uLhOgRztr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotions = {'angry':0, 'disgust':1, 'fear':2, 'happy':3, 'neutral':4, 'ps':5, 'sad':6}\n",
        "#01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
        "emotions_ravdess = {'05':0, '07':1, '06':2, '03':3,'01':4, '04':6, '08':5}\n",
        "emotions_savdee = {'a':0, 'd':1, 'f':2, 'h':3, 'n':4, 'su':5,'sa':6}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpHIuEuhJAha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io.wavfile as wavfile\n",
        "X_raw_data = np.ndarray((4528,23879))\n",
        "y = []\n",
        "i=0\n",
        "max=0\n",
        "#TESS\n",
        "for catalog in tqdm(os.listdir(catalog_name)):\n",
        "  for fn in os.listdir(catalog_name+catalog):\n",
        "    new_record = wavfile.read(catalog_name+catalog+'/'+fn)[1]\n",
        "    #if len(new_record) > max:\n",
        "      #max = len(new_record)\n",
        "    if (np.size(new_record) < 23879):\n",
        "      time_differece = 23879-np.size(new_record)\n",
        "      X_raw_data[i] = np.append(new_record,np.zeros((time_differece)))\n",
        "    else:\n",
        "      X_raw_data[i] = new_record[:23879]  \n",
        "    y.append(emotions[fn.split('_')[2][:-4]])\n",
        "    i+=1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A49WcRlIQTqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RAVDESS\n",
        "for catalog in tqdm(os.listdir(catalog_name_rav)):\n",
        "  for fn in os.listdir(catalog_name_rav+catalog):\n",
        "    if fn.split('-')[2] == '02':\n",
        "      continue\n",
        "    new_record = wavfile.read(catalog_name_rav+catalog+'/'+fn)[1]\n",
        "    if (np.size(new_record) < 23879):\n",
        "      time_differece = 23879- np.size(new_record)\n",
        "      X_raw_data[i] = np.append(new_record,np.zeros((time_differece)))\n",
        "    else:\n",
        "      X_raw_data[i] = new_record[:23879]  \n",
        "    y.append(emotions_ravdess[fn.split('-')[2]])\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv8ciDwGoyz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SAVEE\n",
        "for catalog in tqdm(os.listdir(catalog_name_sav)):\n",
        "  for fn in os.listdir(catalog_name_sav+catalog):\n",
        "    new_record = wavfile.read(catalog_name_sav+catalog+'/'+fn)[1]\n",
        "    if (np.size(new_record) < 23879):\n",
        "      time_differece = 23879-np.size(new_record)\n",
        "      X_raw_data[i] = np.append(new_record,np.zeros((time_differece)))\n",
        "    else:\n",
        "      X_raw_data[i] = new_record[:23879]  \n",
        "    y.append(emotions_savdee[fn.split('.')[0][:-2]])\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X37CzA8do8Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(X_raw_data, \"drive/My Drive/X_raw_data.npy\")\n",
        "np.save(y, \"drive/My Drive/y.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}